{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9a993d180f1a520a86812c8b22f7143bbc0020a"
      },
      "cell_type": "code",
      "source": "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\nfrom sklearn.metrics import log_loss\nimport sys\n\n\nimport os\nimport pandas as pd\n\nimport numpy as np\nfrom glob import glob\nimport cv2\nimport skimage\nfrom skimage.transform import resize\n\nimport keras\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.models import load_model\nimport keras.callbacks as kcall\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\nimport matplotlib.pyplot as plt\nfrom keras.applications.resnet50 import ResNet50\nfrom keras import optimizers, metrics, models\nfrom keras.layers import Input, Flatten, Dense\nfrom keras.optimizers import SGD, Adam, rmsprop\n\n%matplotlib inline",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "469bc6705d524cb8739eefffb752dc19cbdd089c"
      },
      "cell_type": "code",
      "source": "print(os.listdir(\"../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen\"))",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['AKIEC', 'BKL', 'NV', 'MEL', 'VASC', 'DF', 'BCC']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "74272bb10a59f27d58600920f7b08105477b587b"
      },
      "cell_type": "code",
      "source": "resnet50_weights = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'",
      "execution_count": 55,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31fab7218083e8aa3b9e9fc88cf10045cb47167c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "space = {\n         'lr': hp.choice('lr',[0.01, 0.001, 0.0001]),\n#          'dropout': hp.choice('dropout', [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]),\n         'batch_size': hp.choice('batch_size', [32, 64, 128]),\n         'epochs': hp.choice('epochs', [15, 20, 25, 30, 50]),\n#        'optimizer': hp.choice('optimizer',['sgd','adam','rmsprop']),\n#          'activation': hp.choice('activation',['relu',\n#                                                 'tanh']),\n        }",
      "execution_count": 56,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5cd9fc51951d479e3ad77627926397cf4e5ed9e2"
      },
      "cell_type": "code",
      "source": "train_dir = '../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen'\nfor root,dirs,files in os.walk(train_dir):\n    print (root, len(files))",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": "../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen 0\n../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen/AKIEC 327\n../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen/BKL 1099\n../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen/NV 6705\n../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen/MEL 1113\n../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen/VASC 142\n../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen/DF 115\n../input/skin-classification-preprocess-sharpen/train-preprocess-sharpen/train-preprocess-sharpen/BCC 514\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "378d5d9184e33383a6c6ae0531a699df9079b404",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def f_nn(params):   \n    print ('Parameters testing: ', params)\n    batch_size=params['batch_size']\n    epochs=params['epochs']\n    from keras.preprocessing.image import ImageDataGenerator\n\n    # this is the augmentation configuration we will use for training\n    train_datagen = ImageDataGenerator(\n        rescale=1. / 255,\n        shear_range=0.2,\n        zoom_range=0.2,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            fill_mode='nearest',\n        horizontal_flip=True,\n        validation_split=0.25)\n\n    # target_size = (height, width)\n    target_size = (450, 600)\n\n    test_datagen = ImageDataGenerator(rescale=1. / 255)\n\n    train_generator = train_datagen.flow_from_directory(\n            train_dir,\n            target_size = target_size,       \n            class_mode = 'categorical',\n            batch_size=batch_size,\n            subset=\"training\",\n            shuffle = True)\n\n    validation_generator = train_datagen.flow_from_directory(\n            train_dir,\n            target_size = target_size,        \n            class_mode = 'categorical',\n            batch_size = batch_size,\n            subset = \"validation\",\n            shuffle = True)\n\n\n\n    \n    model = Sequential()\n    model.add(ResNet50(include_top=False, pooling='avg', weights=resnet50_weights))\n    model.add(Dense(output_classes, activation='softmax'))\n    model.layers[0].trainable = False\n    model.compile(optimizer = Adam(lr=params['lr']), loss='categorical_crossentropy', metrics=['accuracy'])\n\n    history = model.fit_generator(\n      train_generator,\n      steps_per_epoch = 400,\n      epochs = epochs,\n      validation_data = validation_generator,\n      validation_steps = 100,\n      verbose = 1, callbacks=get_callbacks(params))\n    \n    \n    best_epoch = np.argmax(history.history['val_acc'])\n    best_val_acc = np.max(history.history['val_acc'])\n    print('Epoch {} - val acc: {}'.format(best_epoch, best_val_acc))\n    sys.stdout.flush() \n    \n    return {'val_acc': best_val_acc, 'best_epoch': best_epoch, 'eval_time': time.time(), 'status': STATUS_OK}",
      "execution_count": 58,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eafbf645b66325487fef540b252a782986c921bb"
      },
      "cell_type": "code",
      "source": "# os.mkdir('callbacks')",
      "execution_count": 59,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7261b543321f67fe9f25dee7c402cf832be1e4b6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# os.mkdir('tensor-logs')",
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "191acf8257f07e4bfef42b8554f741051549e00f"
      },
      "cell_type": "code",
      "source": " # !ls",
      "execution_count": 61,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1abd5240499d10fe36059fad182ee6749c72cc5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "output_classes = 7\ninput_shape = (450,600,3)",
      "execution_count": 62,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e3dcb0aca71f03a85b6e4a677a54803937b2341",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def get_callbacks(params):\n    callbacks =[EarlyStopping(monitor='val_acc', patience=5, verbose=1),\n                ModelCheckpoint('callbacks/{}.h5'.format(params['batch_size']), save_best_only=True),\n             TensorBoard('tensor-logs/logs-gridsearch', write_graph=True, write_grads=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)]\n    return callbacks",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ad58082fb3528fe4a93b17b2f2aa5e87712eaded"
      },
      "cell_type": "markdown",
      "source": "____"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58ba906fe86e164a127b64490f6cf81d91955737"
      },
      "cell_type": "code",
      "source": "trials = Trials()\nbest = fmin(f_nn, space, algo=tpe.suggest, max_evals=30, trials=trials)\nprint(best)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Parameters testing:  {'batch_size': 64, 'epochs': 25, 'lr': 0.01}\nFound 7515 images belonging to 7 classes.\nFound 2500 images belonging to 7 classes.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "307852ca436f3b6f178564883600c2b73240b7f7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "831421fc8eed78a8f2a9299b299543e3ab70b293"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}